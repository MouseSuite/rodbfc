{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b11bbf-e8f3-41bf-bb68-300c71cd0c33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047acef-0107-489e-a8ef-b47651165983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from os.path import isfile\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "uncorr_files = glob.glob('/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/*uncorr.nii.gz')\n",
    "print(uncorr_files)\n",
    "\n",
    "\n",
    "for f in uncorr_files:\n",
    "  sub_name = f[:-14]\n",
    "\n",
    "  corr_file = sub_name + '_corr.nii.gz'\n",
    "  uncorr_file = sub_name + '_uncorr.nii.gz'\n",
    "  output_file = sub_name + '_bias.nii.gz'\n",
    "\n",
    "  #if isfile(output_file):\n",
    "  #  continue\n",
    "\n",
    "  print(sub_name)\n",
    "\n",
    "  # Load the NIfTI images using nibabel\n",
    "  image1 = nib.load(corr_file).get_fdata()\n",
    "  image2 = nib.load(uncorr_file).get_fdata().squeeze()\n",
    "\n",
    "\n",
    "\n",
    "  #when we augment, make sure that the log domain is correctly accounted for\n",
    "\n",
    "  # Calculate the ratio of the two images\n",
    "  ratio = np.divide(image2, image1 + 0.1, out=np.zeros_like(image2) ) # added 0.1 to avoid division by 0\n",
    "  ratio[ratio > 10] = 1\n",
    "\n",
    "  # Save the ratio as a NIfTI file\n",
    "  ratio_image = nib.Nifti1Image(ratio, affine=nib.load(uncorr_file).affine)  # Assuming no affine transformation\n",
    "  nib.save(ratio_image, output_file)\n",
    "\n",
    "  print(f\"Ratio image saved as {output_file}\")\n",
    "\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17295aff-69be-483e-9869-58754722d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "\n",
    "#from nilearn.plotting import plot_anat\n",
    "\n",
    "nifti_file1 = '/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/eae14_08_20_uncorr.nii.gz'\n",
    "nifti_file2 = '/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/eae14_08_20_corr.nii.gz'\n",
    "nifti_file3 = '/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/eae14_08_20_bias.nii.gz'\n",
    "\n",
    "# Load the NIfTI file\n",
    "#nifti_img = nib.load(nifti_file)\n",
    "\n",
    "# Plot the image using nilearn\n",
    "#plotting.view_img(nifti_file1, bg_img=False, cmap='gray', colorbar=True, symmetric_cmap=False)\n",
    "\n",
    "plotting.plot_anat(nifti_file1, colorbar=True,vmax=2e4,black_bg='k',cut_coords=(5,13,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ce879-3747-499a-8bcf-2ea82c413c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_anat(nifti_file2, colorbar=True, vmax=2e4,cut_coords=(5,13,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e0536-82de-406c-bab3-f751ef961031",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_anat(nifti_file3, colorbar=True, vmax=2,vmin=0,cut_coords=(5,16,6))\n",
    "plotting.plot_anat(nifti_file3, colorbar=True, vmax=2,vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5cba5-d5ad-4262-9cd3-5a796a4cb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from torch.nn import MSELoss\n",
    "from monai.data import Dataset, DataLoader, partition_dataset\n",
    "from monai.transforms.utility.dictionary import SqueezeDimd\n",
    "from monai.transforms import Compose, LoadImaged, SqueezeDim, SqueezeDimd, ToTensord, LoadImage, ToTensor, EnsureChannelFirstD, EnsureChannelFirst, Resize, RandBiasFieldd\n",
    "from monai.utils import set_determinism\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_determinism(seed=0)\n",
    "\n",
    "# Define your dataset and data loader\n",
    "class BiasFieldCorrectionDataset(Dataset):\n",
    "    def __init__(self, image_files, bias_files, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.bias_files = bias_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(self.image_files[idx])\n",
    "        bias = self.transform(self.bias_files[idx])\n",
    "        return {'image': image, 'bias': bias}\n",
    "\n",
    "# Assuming you have a list of paired image and bias file paths\n",
    "#image_files = ['image1.nii.gz', 'image2.nii.gz']\n",
    "#bias_files = ['bias_field1.nii.gz', 'bias_field2.nii.gz']\n",
    "\n",
    "image_files = (glob('/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/*uncorr.nii.gz'))\n",
    "bias_files = (glob('/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/*bias.nii.gz'))\n",
    "\n",
    "# Define transformations\n",
    "#transforms = Compose([LoadImaged(keys=['image', 'bias'],image_only=True), AddChanneld(keys=['image', 'bias']), ToTensord(keys=['image', 'bias'])])\n",
    "#transforms = Compose([LoadImage(image_only=True), Resize(), EnsureChannelFirst(), ToTensor()])\n",
    "\n",
    "\n",
    "data_dicts = [{\"image\": image, \"bias\": bias} for image, bias in zip(image_files, bias_files)]\n",
    "\n",
    "random.seed(11)\n",
    "\n",
    "#random.shuffle(data_dicts)\n",
    "num_files = len(data_dicts)\n",
    "num_train_files = round(0.8 * num_files)\n",
    "train_files = data_dicts[:num_train_files]\n",
    "val_files = data_dicts[num_train_files:]\n",
    "print(\"total num files:\", len(data_dicts))\n",
    "print(\"num training files:\", len(train_files))\n",
    "print(\"num validation files:\", len(val_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f462d-fd16-42a5-aba5-6576b52a558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from monai.transforms import Compose, Resized, RandBiasFieldd, ScaleIntensityd,LoadImaged, EnsureChannelFirstd, RandAffined, ToTensord,LoadImage,ToTensor,EnsureChannelFirstD,EnsureChannelFirst, Resize, RandBiasFieldd\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    pad_list_data_collate,\n",
    "    TestTimeAugmentation,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "keys = [\"image\", \"bias\"]\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys,image_only=True),\n",
    "    EnsureChannelFirstd(keys),\n",
    "    ScaleIntensityd(keys=\"image\", minv=0.0, maxv=1.0),\n",
    "    RandAffined(\n",
    "            keys,\n",
    "            prob=0.5,\n",
    "            rotate_range=(np.pi / 18, np.pi / 18, np.pi / 18),\n",
    "            translate_range=(5,5,5),\n",
    "            scale_range=(0.3,0.3,0.3),shear_range=(.1,.1,.1,.1,.1,.1),\n",
    "            padding_mode=(\"zeros\",\"reflection\"),\n",
    "        ),\n",
    "    Resized(\n",
    "            keys,\n",
    "            spatial_size=(64, 64, 64),\n",
    "    ),\n",
    "    RandBiasFieldd(keys,prob=0.5, coeff_range=(-1,1)),\n",
    "])\n",
    "\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys,image_only=True),\n",
    "    EnsureChannelFirstd(keys),    \n",
    "    ScaleIntensityd(keys=\"image\", minv=0.0, maxv=1.0),    \n",
    "    Resized(\n",
    "            keys,\n",
    "            spatial_size=(64, 64, 64),\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, num_workers=10, collate_fn=pad_list_data_collate)\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=10, collate_fn=pad_list_data_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed29261-0712-4db1-b0d3-d45fddd8ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "i=0\n",
    "for batch in train_loader:\n",
    "    i += 1\n",
    "    if i>20:\n",
    "        break\n",
    "        \n",
    "    for j in range(4):\n",
    "        print(j)\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(batch['image'][j,0,:,32,:],cmap='gray',vmin=0,vmax=1)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(batch['bias'][j,0,:,32,:],cmap='gray',vmin=-10,vmax=10)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d266b5-a183-445e-a0e5-eec03b2408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create dataset and data loader\n",
    "#dataset = BiasFieldCorrectionDataset(image_files, bias_files, transform=transforms)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "#train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Define the UNet model and optimizer\n",
    "\n",
    "# Specify spatial_dims and strides for 3D data\n",
    "spatial_dims = 3\n",
    "strides = (1, 1, 1, 1)\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=spatial_dims,\n",
    "    in_channels=1,  # Adjust based on your data\n",
    "    out_channels=1, # Adjust based on your data\n",
    "    channels=(2,8,8,16,32),#(16, 64, 64, 128, 256),\n",
    "    strides=strides,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define the Dice loss\n",
    "loss_function = MSELoss() # DiceLoss(sigmoid=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10002\n",
    "save_interval = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        inputs, biases = batch['image'].to(device), torch.log(batch['bias']).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, biases)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss / len(train_loader)}\")\n",
    "\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, biases = batch['image'].to(device), torch.log(batch['bias']).to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, biases)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {total_val_loss / len(val_loader)}\")\n",
    "\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        \n",
    "        # Format the date and time as a string\n",
    "        formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        \n",
    "        # Create a filename with the formatted date and time\n",
    "        filename = f\"models/bias_field_correction_model_{formatted_datetime}_epoch_{epoch}.pth\"\n",
    "        \n",
    "        # Save the trained model\n",
    "        torch.save(model.state_dict(), filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852201dc-9ae0-4a63-8558-5e661138e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import monai\n",
    "except:\n",
    "  !pip install monai pytorch-gpu nilearn\n",
    "  import monai\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from torch.nn import MSELoss\n",
    "from monai.data import Dataset, DataLoader, partition_dataset\n",
    "\n",
    "from monai.transforms import Compose, LoadImaged, ToTensord,LoadImage,ToTensor,EnsureChannelFirstD,EnsureChannelFirstd, Resized, Resize, RandBiasFieldd\n",
    "from monai.utils import set_determinism\n",
    "from glob import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the UNet model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify spatial_dims and strides for 3D data\n",
    "spatial_dims = 3\n",
    "strides = (1, 1, 1, 1)\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=spatial_dims,\n",
    "    in_channels=1,  # Adjust based on your data\n",
    "    out_channels=1, # Adjust based on your data\n",
    "    channels=(2,8,8,16,32),#(16, 64, 64, 128, 256)/8,\n",
    "    strides=strides,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "keys=[\"image\"]\n",
    "\n",
    "test_transforms = Compose([\n",
    "    LoadImaged(keys,image_only=True),\n",
    "    EnsureChannelFirstd(keys),\n",
    "    Resized(\n",
    "            keys,\n",
    "            spatial_size=(64, 64, 64),\n",
    "        ),\n",
    "   # RandBiasField(prob=1, coeff_range=(0.2,0.3)),\n",
    "    #ToTensor(),\n",
    "])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Load the test image (adjust the path to your validation image)\n",
    "test_image_path = '/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/3_RC_uncorr.nii.gz'\n",
    "test_ground_truth_corrected_image_path = '/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/3_RC_corr.nii.gz'\n",
    "test_corrected_image_path = '/project/ajoshi_27/rodent_bfc_data4ML/data4ML2/3_RC_uncorr.bfc.nii.gz'\n",
    "model_file='models/bias_field_correction_model_2023-09-17_02-55-00.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "\n",
    "test_dict = [{\"image\":test_image_path}]\n",
    "#test_dict = [{\"image\": image, \"bias\": bias} for image, bias in zip(image_files, bias_files)]\n",
    "# Apply transformations to the validation image\n",
    "test_image = test_transforms(test_dict)[0][\"image\"].to(device)\n",
    "\n",
    "# Apply the trained model to estimate the bias field\n",
    "with torch.no_grad():\n",
    "    estimated_bias_field = model(test_image[None,])\n",
    "\n",
    "# Convert the estimated bias field to a Numpy array\n",
    "estimated_bias_field = estimated_bias_field.squeeze().cpu().numpy()\n",
    "\n",
    "print(estimated_bias_field.shape)\n",
    "# Load the original validation image without resizing (for displaying the corrected image)\n",
    "original_test_image = nib.load(test_image_path).get_fdata().squeeze()\n",
    "original_test_corrected_image = nib.load(test_ground_truth_corrected_image_path).get_fdata().squeeze()\n",
    "\n",
    "orig_shape = original_test_image.shape\n",
    "\n",
    "print(orig_shape)\n",
    "\n",
    "estimated_bias_field_resized = Resize(spatial_size=orig_shape)(estimated_bias_field[None,])[0]\n",
    "\n",
    "print(estimated_bias_field_resized.shape)\n",
    "# Apply the estimated bias field to correct the original image\n",
    "corrected_image = original_test_image / np.exp(estimated_bias_field_resized)\n",
    "\n",
    "# Display the original image, estimated bias field, and corrected image\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(221)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(original_test_image[:, original_test_image.shape[1] // 2, :].T, cmap='gray')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title(\"Estimated Bias Field\")\n",
    "plt.imshow(estimated_bias_field_resized[:, estimated_bias_field_resized.shape[1] // 2, :].T, cmap='gray')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title(\"Corrected Estimated Image\")\n",
    "plt.imshow(corrected_image[:, corrected_image.shape[1] // 2, :].T, cmap='gray')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title(\"Corrected GT Image\")\n",
    "plt.imshow(original_test_corrected_image[:, original_test_image.shape[1] // 2, :].T, cmap='gray')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "input_nifti = nib.load(test_image_path)\n",
    "input_dtype = input_nifti.get_data_dtype()\n",
    "corrected_image = corrected_image.astype(input_dtype)\n",
    "\n",
    "\n",
    "# Create a new NIfTI image with the result data\n",
    "result_nifti = nib.Nifti1Image(corrected_image, input_nifti.affine)\n",
    "\n",
    "# Save the result as a new NIfTI image\n",
    "nib.save(result_nifti, test_corrected_image_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4a0f5-c5de-4e2c-9d43-ec0a5c809887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
